{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de559df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87a986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_RESULTS_PATHS = glob.glob(\"results/*/*/*.json\")\n",
    "ALL_RESULTS_PATHS[:5], len(ALL_RESULTS_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821e31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DICT = {} # model -> perturbation -> list of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579e273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for result_file in tqdm(ALL_RESULTS_PATHS):\n",
    "    parts = result_file.split(\"\\\\\")\n",
    "    model = parts[1]\n",
    "    perturbation = parts[2]\n",
    "    if perturbation == \"UnitConv\":\n",
    "        continue\n",
    "    q_id = int(parts[3].split(\".\")[0])\n",
    "    \n",
    "    if model not in RESULTS_DICT:\n",
    "        RESULTS_DICT[model] = {}\n",
    "    if perturbation not in RESULTS_DICT[model]:\n",
    "        RESULTS_DICT[model][perturbation] = {}\n",
    "    \n",
    "    with open(result_file, \"r\") as f:\n",
    "        result_data = json.load(f)\n",
    "        RESULTS_DICT[model][perturbation][q_id] = result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a255c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DICT.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b9cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model to size map\n",
    "import math\n",
    "MODEL_SIZE_MAP = {\n",
    "    'openai_gpt_5_2': 1500,\n",
    "    'anthropic_claude_sonnet_4_5': 1500,\n",
    "    'anthropic_claude_haiku_4_5': 1000,\n",
    "    # 'google_gemini_3_pro_preview': 2000,\n",
    "    'openai_gpt_4o_mini': 1000,\n",
    "    'google_gemini_3_flash_preview': 1000,\n",
    "    'deepseek_deepseek_v3_2': 685,\n",
    "    'mistralai_mistral_large_2512': 675,\n",
    "    'qwen_qwen3_235b_a22b_2507': 235,\n",
    "    'meta_llama_llama_3_1_8b_instruct': 8,\n",
    "    'meta_llama_llama_4_scout': 109,\n",
    "    'mistralai_ministral_8b_2512': 8,\n",
    "    'mistralai_ministral_3b': 3,\n",
    "    'google_gemma_3_4b_it': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS_DICT['azure_gpt_4o_mini'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in RESULTS_DICT['openai_gpt_5_2'].keys():\n",
    "    print(key)\n",
    "    q_id_random = list(RESULTS_DICT['openai_gpt_5_2'][key].keys())[0]\n",
    "    print(\"Question ID: \", q_id_random)\n",
    "    print(\"Correct answer: \", RESULTS_DICT['openai_gpt_5_2'][key][q_id_random]['answer'])\n",
    "    print(\"Model answer clean question: \", RESULTS_DICT['openai_gpt_5_2'][key][q_id_random]['answer_solution_clean'])\n",
    "    print(\"Model answer perturbed question: \", RESULTS_DICT['openai_gpt_5_2'][key][q_id_random]['answer_solution_perturbed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c114e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_answer(s):\n",
    "    ANS_RE = re.compile(r\"#### (\\-?[0-9\\.\\,]+)\")\n",
    "    match = ANS_RE.search(s)\n",
    "    if match:\n",
    "        match_str = match.group(1).strip()\n",
    "        match_str = match_str.replace(\",\", \"\")\n",
    "        return match_str\n",
    "    else:\n",
    "        # check if the last part of the string is a number\n",
    "        match_str = s.split()[-1].strip()\n",
    "        if re.match(r'(\\-?[0-9\\.\\,]+)', match_str):\n",
    "            return match_str\n",
    "    return 'invalid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f584e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in RESULTS_DICT.keys():\n",
    "    for perturbation in RESULTS_DICT[model].keys():\n",
    "        for q_id in RESULTS_DICT[model][perturbation].keys():\n",
    "            # if RESULTS_DICT[model][perturbation][q_id]['answer'] is None:\n",
    "            RESULTS_DICT[model][perturbation][q_id]['correct_answer'] = extract_answer(\n",
    "                RESULTS_DICT[model][perturbation][q_id]['solution']\n",
    "            )\n",
    "            if RESULTS_DICT[model][perturbation][q_id]['correct_answer'] != 'invalid':\n",
    "                RESULTS_DICT[model][perturbation][q_id]['correct_answer'] = float(\n",
    "                    RESULTS_DICT[model][perturbation][q_id]['correct_answer']\n",
    "                )\n",
    "            # print(\"Correct answer: \", RESULTS_DICT[model][perturbation][q_id]['correct_answer'])\n",
    "            try:\n",
    "                RESULTS_DICT[model][perturbation][q_id]['is_correct_clean'] = \\\n",
    "                    float(RESULTS_DICT[model][perturbation][q_id]['answer_solution_clean'].strip().lower()) == \\\n",
    "                    RESULTS_DICT[model][perturbation][q_id]['correct_answer']\n",
    "            except:\n",
    "                RESULTS_DICT[model][perturbation][q_id]['is_correct_clean'] = False\n",
    "            \n",
    "            try:\n",
    "                RESULTS_DICT[model][perturbation][q_id]['is_correct_perturbed'] = \\\n",
    "                    float(RESULTS_DICT[model][perturbation][q_id]['answer_solution_perturbed'].strip().lower()) == \\\n",
    "                    RESULTS_DICT[model][perturbation][q_id]['correct_answer']\n",
    "            except:\n",
    "                RESULTS_DICT[model][perturbation][q_id]['is_correct_perturbed'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_and_confusion_matrix(model, perturbation):\n",
    "    results = RESULTS_DICT[model][perturbation]\n",
    "    clean_correct = sum([1 for q_id in results if results[q_id]['is_correct_clean']])\n",
    "    perturbed_correct = sum([1 for q_id in results if results[q_id]['is_correct_perturbed']])\n",
    "    total = len(results)\n",
    "    print(f\"Model: {model}, Perturbation: {perturbation}\")\n",
    "    print(f\"Clean Accuracy: {clean_correct/total:.2%} ({clean_correct}/{total})\")\n",
    "    print(f\"Perturbed Accuracy: {perturbed_correct/total:.2%} ({perturbed_correct}/{total})\")\n",
    "\n",
    "    # from sklearn.metrics import confusion_matrix\n",
    "    # import seaborn as sns\n",
    "    # y_true = []\n",
    "    # y_pred = []\n",
    "    # for q_id in results:\n",
    "    #     y_true.append(int(results[q_id]['is_correct_clean']))\n",
    "    #     y_pred.append(int(results[q_id]['is_correct_perturbed']))\n",
    "    # cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
    "    # print(cm)\n",
    "    # plt.figure(figsize=(6,5))\n",
    "    # sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Incorrect', 'Correct'], yticklabels=['Incorrect', 'Correct'])\n",
    "    # plt.xlabel('Perturbed')\n",
    "    # plt.ylabel('Clean')\n",
    "    # plt.title(f'Confusion Matrix for {model} with {perturbation}')\n",
    "    # plt.show()\n",
    "\n",
    "    clean_corr_perturbed_corr = 0\n",
    "    clean_corr_perturbed_corr_ids = []\n",
    "\n",
    "    clean_corr_perturbed_incorr = 0\n",
    "    clean_corr_perturbed_incorr_ids = []\n",
    "\n",
    "    clean_incorr_perturbed_corr = 0\n",
    "    clean_incorr_perturbed_corr_ids = []\n",
    "\n",
    "    clean_incorr_perturbed_incorr = 0\n",
    "    clean_incorr_perturbed_incorr_ids = []\n",
    "\n",
    "    for q_id in results:\n",
    "        is_clean_correct = results[q_id]['is_correct_clean']\n",
    "        is_perturbed_correct = results[q_id]['is_correct_perturbed']\n",
    "        if is_clean_correct and is_perturbed_correct:\n",
    "            clean_corr_perturbed_corr += 1\n",
    "            clean_corr_perturbed_corr_ids.append(q_id)\n",
    "        elif is_clean_correct and not is_perturbed_correct:\n",
    "            clean_corr_perturbed_incorr += 1\n",
    "            clean_corr_perturbed_incorr_ids.append(q_id)\n",
    "        elif not is_clean_correct and is_perturbed_correct:\n",
    "            clean_incorr_perturbed_corr += 1\n",
    "            clean_incorr_perturbed_corr_ids.append(q_id)\n",
    "        else:\n",
    "            clean_incorr_perturbed_incorr += 1\n",
    "            clean_incorr_perturbed_incorr_ids.append(q_id)\n",
    "\n",
    "    cm = [ \n",
    "        [clean_incorr_perturbed_incorr, clean_incorr_perturbed_corr],\n",
    "        [clean_corr_perturbed_incorr, clean_corr_perturbed_corr]\n",
    "    ]\n",
    "\n",
    "    cm_ids = [\n",
    "        [clean_incorr_perturbed_incorr_ids, clean_incorr_perturbed_corr_ids],\n",
    "        [clean_corr_perturbed_incorr_ids, clean_corr_perturbed_corr_ids]\n",
    "    ]\n",
    "\n",
    "    clean_acc = clean_correct / total\n",
    "    perturbed_acc = perturbed_correct / total\n",
    "\n",
    "    return clean_acc, perturbed_acc, cm, cm_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1deb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_and_confusion_matrix('azure_gpt_4o_mini', 'ExtraSteps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae57ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_and_confusion_matrix('azure_gpt_4o_mini', 'MathError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c04e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_and_confusion_matrix('llama3_1_latest', 'MathError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7ea3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_and_confusion_matrix('azure_gpt_4o_mini', 'SkippedSteps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba46671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_and_confusion_matrix('azure_gpt_4o_mini', 'Sycophancy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141396d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_and_confusion_matrix('azure_gpt_4o_mini', 'UnitConv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25177752",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perturbation in RESULTS_DICT['openai_gpt_5_2'].keys():\n",
    "    accuracy_and_confusion_matrix('openai_gpt_5_2', perturbation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ef627",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perturbation in RESULTS_DICT['openai_gpt_4o_mini'].keys():\n",
    "    accuracy_and_confusion_matrix('openai_gpt_4o_mini', perturbation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fcb358",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perturbation in RESULTS_DICT['google_gemini_3_flash_preview'].keys():\n",
    "    accuracy_and_confusion_matrix('google_gemini_3_flash_preview', perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9e194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perturbation in RESULTS_DICT['mistralai_mistral_large_2512'].keys():\n",
    "    accuracy_and_confusion_matrix('mistralai_mistral_large_2512', perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c78f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perturbation in RESULTS_DICT['mistralai_ministral_8b_2512'].keys():\n",
    "    accuracy_and_confusion_matrix('mistralai_ministral_8b_2512', perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perturbation in RESULTS_DICT['qwen_qwen3_235b_a22b_2507'].keys():\n",
    "    accuracy_and_confusion_matrix('qwen_qwen3_235b_a22b_2507', perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbece9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for perturbation in RESULTS_DICT['google_gemma_3_27b_it'].keys():\n",
    "#     accuracy_and_confusion_matrix('google_gemma_3_27b_it', perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb62dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for perturbation in RESULTS_DICT['deepseek_deepseek_v3_2'].keys():\n",
    "    accuracy_and_confusion_matrix('deepseek_deepseek_v3_2', perturbation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ce1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4312594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for llm in RESULTS_DICT.keys():\n",
    "    accuracy_results[llm] = {}\n",
    "    for perturbation in RESULTS_DICT[llm].keys():\n",
    "        accuracy_results[llm][perturbation] = {}\n",
    "        clean_acc, perturbed_acc, cm, cm_ids = accuracy_and_confusion_matrix(llm, perturbation)\n",
    "\n",
    "        clean_corr_perturbed_corr = cm[1][1]\n",
    "        clean_corr_perturbed_incorr = cm[1][0]\n",
    "        clean_incorr_perturbed_corr = cm[0][1]\n",
    "        clean_incorr_perturbed_incorr = cm[0][0]\n",
    "\n",
    "        clean_corr_perturbed_corr_ids = cm_ids[1][1]\n",
    "        clean_corr_perturbed_incorr_ids = cm_ids[1][0]\n",
    "        clean_incorr_perturbed_corr_ids = cm_ids[0][1]\n",
    "        clean_incorr_perturbed_incorr_ids = cm_ids[0][0]\n",
    "\n",
    "        accuracy_results[llm][perturbation]['clean_accuracy'] = clean_acc\n",
    "        accuracy_results[llm][perturbation]['perturbed_accuracy'] = perturbed_acc\n",
    "        accuracy_results[llm][perturbation]['clean_corr_perturbed_corr'] = int(clean_corr_perturbed_corr)\n",
    "        accuracy_results[llm][perturbation]['clean_corr_perturbed_incorr'] = int(clean_corr_perturbed_incorr)\n",
    "        accuracy_results[llm][perturbation]['clean_incorr_perturbed_corr'] = int(clean_incorr_perturbed_corr)\n",
    "        accuracy_results[llm][perturbation]['clean_incorr_perturbed_incorr'] = int(clean_incorr_perturbed_incorr)\n",
    "        accuracy_results[llm][perturbation]['clean_corr_perturbed_corr_ids'] = clean_corr_perturbed_corr_ids\n",
    "        accuracy_results[llm][perturbation]['clean_corr_perturbed_incorr_ids'] = clean_corr_perturbed_incorr_ids\n",
    "        accuracy_results[llm][perturbation]['clean_incorr_perturbed_corr_ids'] = clean_incorr_perturbed_corr_ids\n",
    "        accuracy_results[llm][perturbation]['clean_incorr_perturbed_incorr_ids'] = clean_incorr_perturbed_incorr_ids\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26603fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"results/accuracy_summary.json\", \"w\") as f:\n",
    "    json.dump(accuracy_results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc3345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy summary without ids\n",
    "accuracy_summary_no_ids = {}\n",
    "for llm in accuracy_results.keys():\n",
    "    accuracy_summary_no_ids[llm] = {}\n",
    "    for perturbation in accuracy_results[llm].keys():\n",
    "        accuracy_summary_no_ids[llm][perturbation] = {\n",
    "            'clean_accuracy': accuracy_results[llm][perturbation]['clean_accuracy'],\n",
    "            'perturbed_accuracy': accuracy_results[llm][perturbation]['perturbed_accuracy'],\n",
    "            'clean_corr_perturbed_corr': accuracy_results[llm][perturbation]['clean_corr_perturbed_corr'],\n",
    "            'clean_corr_perturbed_incorr': accuracy_results[llm][perturbation]['clean_corr_perturbed_incorr'],\n",
    "            'clean_incorr_perturbed_corr': accuracy_results[llm][perturbation]['clean_incorr_perturbed_corr'],\n",
    "            'clean_incorr_perturbed_incorr': accuracy_results[llm][perturbation]['clean_incorr_perturbed_incorr'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dfb2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/accuracy_summary_no_ids.json\", \"w\") as f:\n",
    "    json.dump(accuracy_summary_no_ids, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30cf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique perturbation types\n",
    "perturbation_types = set()\n",
    "for model_data in accuracy_summary_no_ids.values():\n",
    "    perturbation_types.update(model_data.keys())\n",
    "perturbation_types = sorted(perturbation_types)\n",
    "\n",
    "# Create a separate table for each perturbation type\n",
    "all_tables = []\n",
    "\n",
    "for pert in perturbation_types:\n",
    "    latex = []\n",
    "    latex.append(\"\\\\begin{table}[h]\")\n",
    "    latex.append(\"\\\\centering\")\n",
    "    latex.append(\"\\\\begin{tabular}{lccc}\")\n",
    "    latex.append(\"\\\\hline\")\n",
    "    latex.append(\"Model & Clean & Perturbed & Diff \\\\\\\\\")\n",
    "    latex.append(\"\\\\hline\")\n",
    "    \n",
    "    # Check if any model has data for this perturbation\n",
    "    has_data = False\n",
    "    clean_accs = []\n",
    "    perturbed_accs = []\n",
    "    diffs = []\n",
    "    \n",
    "    for model_name, model_data in accuracy_summary_no_ids.items():\n",
    "        # Clean up model name for display\n",
    "        display_name = model_name.replace(\"_\", \" \").title()\n",
    "        \n",
    "        if pert in model_data and model_data[pert]:\n",
    "            clean = model_data[pert].get(\"clean_accuracy\", \"\")\n",
    "            perturbed = model_data[pert].get(\"perturbed_accuracy\", \"\")\n",
    "            \n",
    "            if clean != \"\" and perturbed != \"\":\n",
    "                diff = perturbed - clean\n",
    "                latex.append(f\"{display_name} & {clean:.2f} & {perturbed:.2f} & {diff:+.2f} \\\\\\\\\")\n",
    "                has_data = True\n",
    "                clean_accs.append(clean)\n",
    "                perturbed_accs.append(perturbed)\n",
    "                diffs.append(diff)\n",
    "    \n",
    "    # Only add the table if it has data\n",
    "    if has_data:\n",
    "        # Calculate averages\n",
    "        avg_clean = np.mean(clean_accs)\n",
    "        avg_perturbed = np.mean(perturbed_accs)\n",
    "        avg_diff = np.mean(diffs)\n",
    "        \n",
    "        latex.append(\"\\\\hline\")\n",
    "        latex.append(f\"Average & {avg_clean:.3f} & {avg_perturbed:.3f} & {avg_diff:+.3f} \\\\\\\\\")\n",
    "        latex.append(\"\\\\hline\")\n",
    "        latex.append(\"\\\\end{tabular}\")\n",
    "        latex.append(f\"\\\\caption{{Model accuracy for {pert} perturbation}}\")\n",
    "        latex.append(f\"\\\\label{{tab:{pert.lower()}}}\")\n",
    "        latex.append(\"\\\\end{table}\")\n",
    "        latex.append(\"\")  # Add blank line between tables\n",
    "        \n",
    "        all_tables.append(\"\\n\".join(latex))\n",
    "\n",
    "# Print all tables\n",
    "print(\"\\n\".join(all_tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7022f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRESENTABLE_NAMES = {\n",
    "    \"ExtraSteps\": \"Extra Steps\",\n",
    "    \"MathError\": \"Math Error\",\n",
    "    \"SkippedSteps\": \"Skipped Steps\",\n",
    "    \"Sycophancy\": \"Sycophancy\",\n",
    "    \"UnitConvFinal\": \"Unit Conversion\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed492dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# perturbation wise density plot of accuracies for both clean and perturbed in different colours\n",
    "for perturbation in perturbation_types:\n",
    "    clean_accuracies = []\n",
    "    perturbed_accuracies = []\n",
    "    \n",
    "    for model_name, model_data in accuracy_summary_no_ids.items():\n",
    "        if perturbation in model_data and model_data[perturbation]:\n",
    "            clean_acc = model_data[perturbation].get(\"clean_accuracy\", None)\n",
    "            perturbed_acc = model_data[perturbation].get(\"perturbed_accuracy\", None)\n",
    "            if clean_acc is not None and perturbed_acc is not None:\n",
    "                clean_accuracies.append(clean_acc)\n",
    "                perturbed_accuracies.append(perturbed_acc)\n",
    "    \n",
    "    # Print statistics\n",
    "    print(f\"\\n{PRESENTABLE_NAMES.get(perturbation, perturbation)} Perturbation:\")\n",
    "    print(f\"  Clean Accuracy    - Mean: {np.mean(clean_accuracies):.4f}, Std: {np.std(clean_accuracies):.4f}\")\n",
    "    print(f\"  Perturbed Accuracy - Mean: {np.mean(perturbed_accuracies):.4f}, Std: {np.std(perturbed_accuracies):.4f}\")\n",
    "    \n",
    "    # Plot density plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    \n",
    "    # Create density estimates\n",
    "    if len(clean_accuracies) > 1:\n",
    "        kde_clean = gaussian_kde(clean_accuracies)\n",
    "        x_range = np.linspace(0, 2, 1000)\n",
    "        ax.fill_between(x_range, kde_clean(x_range), alpha=0.5, label='Clean Accuracy', color='skyblue')\n",
    "        ax.plot(x_range, kde_clean(x_range), color='blue', linewidth=2)\n",
    "    \n",
    "    if len(perturbed_accuracies) > 1:\n",
    "        kde_perturbed = gaussian_kde(perturbed_accuracies)\n",
    "        ax.fill_between(x_range, kde_perturbed(x_range), alpha=0.5, label='Perturbed Accuracy', color='salmon')\n",
    "        ax.plot(x_range, kde_perturbed(x_range), color='red', linewidth=2)\n",
    "    \n",
    "    ax.axvline(np.mean(clean_accuracies), color='blue', linestyle='--', label=f'Clean Mean: {np.mean(clean_accuracies):.2f}')\n",
    "    ax.axvline(np.mean(perturbed_accuracies), color='red', linestyle='--', label=f'Perturbed Mean: {np.mean(perturbed_accuracies):.2f}')\n",
    "    \n",
    "    ax.set_xlabel('Accuracy')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'Accuracy Distribution for {PRESENTABLE_NAMES.get(perturbation, perturbation)} Perturbation')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(0, 2)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a6d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy scatter plot for each perturbation type, w.r.t model size\n",
    "for perturbation in perturbation_types:\n",
    "    model_sizes = []\n",
    "    clean_accuracies = []\n",
    "    perturbed_accuracies = []\n",
    "    accuracy_diffs = []\n",
    "    \n",
    "    for model_name, model_data in accuracy_summary_no_ids.items():\n",
    "        if perturbation in model_data and model_data[perturbation]:\n",
    "            clean_acc = model_data[perturbation].get(\"clean_accuracy\", None)\n",
    "            perturbed_acc = model_data[perturbation].get(\"perturbed_accuracy\", None)\n",
    "            if clean_acc is not None and perturbed_acc is not None:\n",
    "                size = MODEL_SIZE_MAP.get(model_name, None)\n",
    "                if size is not None:\n",
    "                    log_size = math.log10(size)\n",
    "                    model_sizes.append(log_size)\n",
    "                    clean_accuracies.append(clean_acc)\n",
    "                    perturbed_accuracies.append(perturbed_acc)\n",
    "                    accuracy_diff = clean_acc - perturbed_acc\n",
    "                    accuracy_diffs.append(accuracy_diff)\n",
    "\n",
    "    \n",
    "    # Plot scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.scatter(model_sizes, accuracy_diffs, label='Accuracy Difference (Clean - Perturbed)', color='purple', s=100, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    # Add regression line\n",
    "    if len(model_sizes) > 1:\n",
    "        z = np.polyfit(model_sizes, accuracy_diffs, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax.plot(model_sizes, p(model_sizes), \"r--\", alpha=0.8, label=f'Regression: y={z[0]:.3f}x+{z[1]:.3f}')\n",
    "    \n",
    "    ax.set_xlabel('Log10(Model Size) (Billion Parameters)')\n",
    "    ax.set_ylabel('Accuracy Difference (Clean - Perturbed)')\n",
    "    ax.set_title(f'Accuracy vs Model Size for {PRESENTABLE_NAMES.get(perturbation, perturbation)} Perturbation')\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    # Save the figures also\n",
    "    os.makedirs(\"result_plots/accuracy_vs_model_size\", exist_ok=True)\n",
    "    fig.savefig(f\"result_plots/accuracy_vs_model_size/{perturbation}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40c0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Simple_Completions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
